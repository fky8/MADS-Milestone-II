{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7ad4e8-9a69-46ca-bebf-7a542d8f437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SCRAPING YEAR 2025 =====\n",
      "→ Date: 2025/01/01\n",
      "  • Course: HV\n",
      "    – no Race#1 → skipping HV on 2025/01/01\n",
      "  • Course: ST\n",
      "    ✔ Race#1: 12 rows\n",
      "    ✔ Race#2: 14 rows\n",
      "    ✔ Race#3: 12 rows\n",
      "    ✔ Race#4: 6 rows\n",
      "    ✔ Race#5: 14 rows\n",
      "    ✔ Race#6: 14 rows\n",
      "    ✔ Race#7: 14 rows\n",
      "    ✔ Race#8: 11 rows\n",
      "    ✔ Race#9: 12 rows\n",
      "    ✔ Race#10: 12 rows\n",
      "    ✔ Race#11: 15 rows\n",
      "    – Race#12 missing → stop this course\n",
      "→ Date: 2025/01/02\n",
      "  • Course: HV\n",
      "    – no Race#1 → skipping HV on 2025/01/02\n",
      "  • Course: ST\n",
      "    – no Race#1 → skipping ST on 2025/01/02\n",
      "\n",
      " Reached today's date (2025-01-02), stopping.\n",
      "\n",
      " Year 2025 complete: saved 136 rows → RacePlaceData_2025.csv\n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# ─── CONFIG ────────────────────────────────────────────────────────────────\n",
    "START_YEAR = 2025\n",
    "\n",
    "# Selenium: headless Chrome (change path if needed)\n",
    "chrome_opts = Options()\n",
    "chrome_opts.add_argument(\"--headless\")\n",
    "chrome_opts.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(options=chrome_opts)\n",
    "\n",
    "# XPath to the results table on each page\n",
    "TABLE_XPATH = '//*[@id=\"innerContent\"]/div[2]/div[5]/table'\n",
    "\n",
    "# ─── DETERMINE LAST FULL YEAR ──────────────────────────────────────────────\n",
    "today = date.today()\n",
    "today = date(2025, 1, 2)\n",
    "LAST_FULL_YEAR = today.year - 1\n",
    "END_YEAR = today.year  # includes the current year\n",
    "\n",
    "# ─── YEAR LOOP ──────────────────────────────────────────────────────────────\n",
    "for year in range(START_YEAR, END_YEAR + 1):\n",
    "    print(f\"\\n===== SCRAPING YEAR {year} =====\")\n",
    "    df_year = None\n",
    "\n",
    "    # define 1-Jan and 31-Dec for this year\n",
    "    day_cursor = date(year, 1, 1)\n",
    "    year_end   = date(year, 12, 31)\n",
    "    one_day    = timedelta(days=1)\n",
    "\n",
    "    # LOOP ALL DATES IN YEAR\n",
    "    while day_cursor <= year_end:\n",
    "        ds = day_cursor.strftime(\"%Y/%m/%d\")\n",
    "        print(f\"→ Date: {ds}\")\n",
    "\n",
    "        # for each racecourse\n",
    "        for course in (\"HV\", \"ST\"):\n",
    "            print(f\"  • Course: {course}\")\n",
    "\n",
    "            # Scraping Rule: Race 1 must exist\n",
    "            url1 = (\n",
    "              \"https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx\"\n",
    "              f\"?RaceDate={ds}&Racecourse={course}&RaceNo=1\"\n",
    "            )\n",
    "            driver.get(url1)\n",
    "\n",
    "            try:\n",
    "                tbl1 = driver.find_element(By.XPATH, TABLE_XPATH)\n",
    "            except:\n",
    "                print(f\"    – no Race#1 → skipping {course} on {ds}\")\n",
    "                continue   # next course\n",
    "\n",
    "            # scrape Race#1\n",
    "            html1 = tbl1.get_attribute(\"outerHTML\")\n",
    "            tables = pd.read_html(StringIO(html1))\n",
    "            if not tables:\n",
    "                print(f\"    – Race#1 empty → skipping {course} on {ds}\")\n",
    "                continue\n",
    "            df = tables[0]\n",
    "            df[\"Date\"]       = ds\n",
    "            df[\"Course\"]     = course\n",
    "            df[\"RaceNumber\"] = 1\n",
    "            df_year = df if df_year is None else pd.concat([df_year, df], ignore_index=True)\n",
    "            print(f\"    ✔ Race#1: {len(df)} rows\")\n",
    "\n",
    "            # scrape Race#2…Race#12 until one is missing\n",
    "            for race_no in range(2, 13):\n",
    "                url = (\n",
    "                  \"https://racing.hkjc.com/racing/information/English/Racing/LocalResults.aspx\"\n",
    "                  f\"?RaceDate={ds}&Racecourse={course}&RaceNo={race_no}\"\n",
    "                )\n",
    "                driver.get(url)\n",
    "                # time.sleep(1)\n",
    "\n",
    "                try:\n",
    "                    tbl = driver.find_element(By.XPATH, TABLE_XPATH)\n",
    "                except:\n",
    "                    print(f\"    – Race#{race_no} missing → stop this course\")\n",
    "                    break\n",
    "\n",
    "                html = tbl.get_attribute(\"outerHTML\")\n",
    "                tbls = pd.read_html(StringIO(html))\n",
    "                if not tbls:\n",
    "                    print(f\"    – Race#{race_no} empty → stop this course\")\n",
    "                    break\n",
    "\n",
    "                df = tbls[0]\n",
    "                df[\"Date\"]       = ds\n",
    "                df[\"Course\"]     = course\n",
    "                df[\"RaceNumber\"] = race_no\n",
    "                try:\n",
    "                    extra_tbl_xpath = '//*[@id=\"innerContent\"]/div[2]/div[4]/table'\n",
    "                    extra_tbl = driver.find_element(By.XPATH, extra_tbl_xpath)\n",
    "                    extra_html = extra_tbl.get_attribute(\"outerHTML\")\n",
    "                    extra_tables = pd.read_html(StringIO(extra_html))\n",
    "                    if extra_tables:\n",
    "                        meta_df = extra_tables[0]\n",
    "                        meta_texts = meta_df.astype(str).values.flatten()\n",
    "                        meta_dict = {}\n",
    "\n",
    "                        for i, text in enumerate(meta_texts):\n",
    "                            if \"Class\" in text and \"-\" in text:\n",
    "                                parts = text.split(\" - \")\n",
    "                                meta_dict[\"Class\"] = parts[0].replace(\"Class\", \"\").strip()\n",
    "                                meta_dict[\"Distance\"] = parts[1].split()[0].strip()\n",
    "                                meta_dict[\"Score range\"] = parts[1].split(\"-\")[-1].strip(\"()\")\n",
    "                            if \"Going\" in text:\n",
    "                                meta_dict[\"Going\"] = meta_texts[i+1].strip()\n",
    "                            if \"Course\" in text:\n",
    "                                meta_dict[\"Course Detail\"] = meta_texts[i+1].strip()\n",
    "                            if \"Time :\" in text:\n",
    "                                times = [t.strip(\"()\") for t in meta_texts[i+1:i+6] if t.startswith(\"(\")]\n",
    "                                for idx, val in enumerate(times, start=1):\n",
    "                                    meta_dict[f\"Time {idx}\"] = val\n",
    "                                for idx in range(len(times)+1, 6):\n",
    "                                    meta_dict[f\"Time {idx}\"] = float(\"nan\")\n",
    "                            if \"Sectional Time\" in text:\n",
    "                                sects = [meta_texts[i+j].strip() for j in range(1, 6) if i+j < len(meta_texts) and meta_texts[i+j].strip()]\n",
    "                                for idx, val in enumerate(sects, start=1):\n",
    "                                    meta_dict[f\"Sectional Time {idx}\"] = val\n",
    "                                for idx in range(len(sects)+1, 6):\n",
    "                                    meta_dict[f\"Sectional Time {idx}\"] = float(\"nan\")\n",
    "\n",
    "                        for key, val in meta_dict.items():\n",
    "                            df[key] = val\n",
    "                except:\n",
    "                    print(\"    – metadata extraction failed → continuing\")\n",
    "                df_year = df if df_year is None else pd.concat([df_year, df], ignore_index=True)\n",
    "                print(f\"    ✔ Race#{race_no}: {len(df)} rows\")\n",
    "        # Stop scraping if today is reached\n",
    "        if day_cursor == today:\n",
    "            print(f\"\\n Reached today's date ({today}), stopping.\")\n",
    "            break\n",
    "            \n",
    "        # next day\n",
    "        day_cursor += one_day\n",
    "\n",
    "    # after finishing the year, write it out\n",
    "    if df_year is not None:\n",
    "        out_fn = f\"RacePlaceData_{year}.csv\"\n",
    "        df_year.to_csv(out_fn, index=False)\n",
    "        print(f\"\\n Year {year} complete: saved {len(df_year)} rows → {out_fn}\")\n",
    "    else:\n",
    "        print(f\"\\n Year {year} yielded no data, skipping file.\")\n",
    "\n",
    "# cleanup\n",
    "driver.quit()\n",
    "print(\"\\nAll done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465ab4d6-ab1e-44a0-83bb-542e94b74dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
